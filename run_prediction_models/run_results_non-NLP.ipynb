{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import helpers_and_variables as hlp\n",
    "import ML_helpers as ml_hlp\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remaining columns:  472\n",
      "remaining columns:  75\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "read the row data as pd data frame\n",
    "\"\"\"\n",
    "dataPath = \".../PekLUng.xlsx\"\n",
    "password = None#\n",
    "rawdataDF = hlp.get_exL_df(stringPath=dataPath, password=password, sheetNum=1)\n",
    "rawdataDF = rawdataDF.iloc[1: , :]\n",
    "\n",
    "\"\"\" \n",
    "read the data info as pd data frame\n",
    "\"\"\"\n",
    "dataInfoPath = \".../Datainformation.xlsx\"\n",
    "dataInfoDF = hlp.get_cleaned_dataInfo_df(dataInfoPath)\n",
    "katInfoDF = hlp.get_cleaned_katInfo_df(dataInfoPath)\n",
    "\"\"\"\n",
    "get dictionary of data information from data info data fram\n",
    "\"\"\"\n",
    "dict_of_katInfo = hlp.get_dict_of_katInfoDF(katInfoDF)\n",
    "dict_of_dataInfo = hlp.get_dict_of_dataInfoDF(dataInfoDF)\n",
    "\"\"\" \n",
    "Get the labels, under name Lungcancer_Num\n",
    "check whether labels are 1=yes LC or 2=No LC and check STUDY_1 if valid, remove unlabeled and invalid patients\n",
    "\n",
    "\"\"\"\n",
    "rawdataDF, labels = hlp.get_labels_and_indices_unlabeled_patients(rawdataDF)\n",
    "\n",
    "target = pd.DataFrame(data=labels, index=rawdataDF.index)\n",
    "target.columns = ['Lungcancer_Num']\n",
    "# 1 yes have LC, 0 No dont have LC \n",
    "target = target.Lungcancer_Num.apply(lambda x: 0 if x == 2 else 1)\n",
    "labels = target\n",
    "del target\n",
    "hlp.write_list_as_json_file(list(labels))\n",
    "\"\"\"\n",
    "Remove features, which includes information about the label inlucding Lungcancer_num, like diagnos2, aslo modules names\n",
    "DiagnosticInvestigation (need to be discussed, since it includes dignostic which means non early prediction).\n",
    "columns_tobe_removed=None --> predefind columns will be removed, see the function in helpers_and_variables file.\n",
    "remove_cols_with_dates=True --> removes all columns with dates(this is relevance in case of tfidf), \n",
    "otherwise consider using converting dates to days, see function hlp.get_dates_in_days() in next cell.\n",
    "\"\"\"\n",
    "copy_rawdata =  hlp.get_dataframe_without_cols(rawdataDF, columns_tobe_removed=None, remove_cols_with_dates=True)\n",
    "levitsky_rawdata = hlp.get_dataframe_with_specific_cols(rawdataDF)\n",
    "del rawdataDF\n",
    "copy_rawdata = hlp.get_clearedNA_dataFram(copy_rawdata)\n",
    "levitsky_rawdata = hlp.get_clearedNA_dataFram(levitsky_rawdata)\n",
    "copy_rawdata = copy_rawdata.drop(columns=['Patient'], inplace=False)\n",
    "levitsky_rawdata = levitsky_rawdata.drop(columns=['Patient'], inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the data\n",
    "min_max = preprocessing.MinMaxScaler()\n",
    "scaled_values = min_max.fit_transform(copy_rawdata.values)\n",
    "copy_rawdata = pd.DataFrame(data=scaled_values, columns = copy_rawdata.columns, index=copy_rawdata.index)\n",
    "\n",
    "scaled_values = min_max.fit_transform(levitsky_rawdata.values)\n",
    "levitsky_rawdata = pd.DataFrame(data=scaled_values, columns = levitsky_rawdata.columns, index=levitsky_rawdata.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 background\n",
    "backgroud_variables = levitsky_rawdata[levitsky_rawdata.columns[0:7]]\n",
    "# 63 descriptors\n",
    "descriptors = levitsky_rawdata[levitsky_rawdata.columns[7:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pyopls import OPLS\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import  roc_auc_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# from time import time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy\n",
    "from scipy.stats import randint\n",
    "from sklearn.utils.fixes import loguniform\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# (cv folds, split size)\n",
    "# combinations = [(6, 0.15)]\n",
    "\n",
    "combinations = [(5, 0.2)]\n",
    "all_test_dicts = dict()\n",
    "\n",
    "vectorizer = 'None'\n",
    "random_state = 42\n",
    "n_iter = 220\n",
    "\n",
    "data_dfs = [copy_rawdata, levitsky_rawdata, descriptors, backgroud_variables]\n",
    "data_dfs_names = ['All', '70 variables','63 descriptors ', '7 back. variables']\n",
    "\n",
    "\n",
    "for combs in combinations:\n",
    "    cv = combs[0]\n",
    "    split_size = combs[1]\n",
    "    \n",
    "    print(\"started for cv and split size combs, \", cv, split_size)\n",
    "    results = dict(); opls_dict = dict(); svm_dict = dict(); rf_dict = dict(); knn_dict = dict(); mlp_dict = dict(); \n",
    "    dict_best_params = dict()\n",
    "\n",
    "    best_test = [0 for i in range(len(data_dfs_names))]\n",
    "    best_test_model = ['' for i in range(len(data_dfs_names))]\n",
    "    \n",
    "    for idx in range(len(data_dfs)):\n",
    "        data_df = data_dfs[idx]\n",
    "\n",
    "        x_train, x_test, y_train, y_test = ml_hlp.get_train_test_split_data(data_df,\n",
    "                                                                            labels,\n",
    "                                                                            stratify = labels,\n",
    "                                                                            test_size=split_size,\n",
    "                                                                            random_state=random_state,\n",
    "                                                                            shuffle = True)\n",
    "        print(\"Number of features for each patient is: \", len(data_df.columns))\n",
    "#         del all_data_matrix, min_max, scaled_data\n",
    "\n",
    "        X_train = ml_hlp.get_csr_matrix(x_train)\n",
    "        X_test = ml_hlp.get_csr_matrix(x_test)\n",
    "        Y_train = np.array(y_train, dtype='float')\n",
    "        Y_test = np.array(y_test, dtype='float')\n",
    "\n",
    "        opls = OPLS(2)\n",
    "        opls.fit(X_train, Y_train)\n",
    "        z_train = opls.transform(X_train)\n",
    "        z_test = opls.transform(X_test)\n",
    "        pls = PLSRegression(1)\n",
    "        pls.fit(z_train, Y_train)\n",
    "\n",
    "        y_pred = cross_val_predict(pls, z_train, Y_train, cv=StratifiedKFold(cv))\n",
    "        threshed_values = np.array(y_pred)\n",
    "        best = 0\n",
    "        best_thresh = 0\n",
    "        for thresh in np.unique(y_pred):\n",
    "            threshed_values[y_pred<thresh]=1\n",
    "            threshed_values[y_pred>=thresh]=2\n",
    "            score = roc_auc_score(Y_train, threshed_values)\n",
    "            if score > best:\n",
    "                best=score\n",
    "                best_thresh=thresh\n",
    "                \n",
    "        std = y_pred[y_pred>=best_thresh].std()\n",
    "        \n",
    "        y_pred[y_pred<best_thresh]=1\n",
    "        y_pred[y_pred>=best_thresh]=2\n",
    "        cv_score = roc_auc_score(Y_train, y_pred)\n",
    "        \n",
    "        y_pred = pls.predict(z_train)\n",
    "        y_pred[y_pred<best_thresh]=1\n",
    "        y_pred[y_pred>=best_thresh]=2\n",
    "        train_score = roc_auc_score(Y_train, y_pred)\n",
    "        \n",
    "        y_pred = pls.predict(z_test)\n",
    "        y_pred[y_pred<best_thresh]=1\n",
    "        y_pred[y_pred>=best_thresh]=2\n",
    "        test_score = roc_auc_score(Y_test, y_pred)\n",
    "        f1_Score = f1_score(Y_test, y_pred,  average='weighted')\n",
    "        \n",
    "        dict_best_params['opls '+ data_dfs_names[idx]] = {'best_thresh': best_thresh}\n",
    "        \n",
    "        opls_dict[data_dfs_names[idx]] = {'Train': [train_score], \n",
    "                            'CV {0}'.format(cv): [cv_score, std],\n",
    "                            'Test' : [test_score, f1_Score]}\n",
    "\n",
    "        if test_score > best_test[idx]:\n",
    "            best_test[idx] = test_score\n",
    "            best_test_model[idx] = 'opls'\n",
    "\n",
    "        del opls, pls\n",
    "        svm = SVC(probability=True, \n",
    "              random_state=random_state, class_weight = \"balanced\")\n",
    "\n",
    "        param_distributions = {\"gamma\": loguniform(0.0001, 2),\n",
    "                               \"kernel\": ['rbf', 'linear'],\n",
    "                               \"degree\": [2,3],\n",
    "                               \"C\": loguniform(0.001, 2)\n",
    "                               }\n",
    "        search = RandomizedSearchCV(svm, param_distributions,\n",
    "                                       n_iter= n_iter,\n",
    "                                       verbose = 0,\n",
    "                                       cv = StratifiedKFold(cv),\n",
    "                                       n_jobs=-1,\n",
    "                                       error_score='raise',\n",
    "                                       random_state=random_state).fit(X_train, Y_train)\n",
    "        svm = search.best_estimator_\n",
    "        dict_best_params['svm '+ data_dfs_names[idx]] = search.best_params_\n",
    "\n",
    "        cv_score = cross_val_score(svm, X_train, Y_train,  cv=StratifiedKFold(cv), n_jobs=-1, scoring='roc_auc', error_score='raise')\n",
    "        test_score = ml_hlp.get_AUC_ROC_value(X_test, Y_test, svm)\n",
    "\n",
    "        svm_dict[data_dfs_names[idx]] = {'Train': [ml_hlp.get_AUC_ROC_value(X_train, Y_train, svm)], \n",
    "                            'CV {0}'.format(cv): [cv_score.mean(), cv_score.std()],\n",
    "                            'Test' : [test_score,  f1_score(Y_test, svm.predict(X_test), average='weighted')]}\n",
    "        if test_score > best_test[idx]:\n",
    "            best_test[idx] = test_score\n",
    "            best_test_model[idx] = 'svm'\n",
    "\n",
    "\n",
    "        del svm\n",
    "        rf = RandomForestClassifier(random_state=random_state, \n",
    "                                    class_weight = \"balanced\", \n",
    "                                    max_features='auto',\n",
    "                                    criterion='entropy')\n",
    "\n",
    "        param_distributions = {\"max_depth\": [1, 2, 3, None],\n",
    "                               \"min_samples_split\": randint(2, 14),\n",
    "                               \"min_samples_leaf\": randint(1, 14),\n",
    "                               \"ccp_alpha\": loguniform(0.0001, 1)\n",
    "                              }\n",
    "        search = RandomizedSearchCV(rf, param_distributions,\n",
    "                                       n_iter=n_iter,\n",
    "                                       verbose = 0,\n",
    "                                       cv = StratifiedKFold(cv),\n",
    "                                       n_jobs=-1,\n",
    "                                       error_score = 'raise',\n",
    "                                       random_state=random_state).fit(X_train, Y_train)\n",
    "        rf = search.best_estimator_\n",
    "        dict_best_params['rf '+ data_dfs_names[idx]] = search.best_params_\n",
    "\n",
    "        cv_score = cross_val_score(rf, X_train, Y_train,  cv=StratifiedKFold(cv), n_jobs=-1, scoring='roc_auc', error_score='raise')\n",
    "        test_score = ml_hlp.get_AUC_ROC_value(X_test, Y_test, rf)\n",
    "        rf_dict[data_dfs_names[idx]] = {'Train': [ml_hlp.get_AUC_ROC_value(X_train, Y_train, rf)], \n",
    "                            'CV {0}'.format(cv): [cv_score.mean(), cv_score.std()],\n",
    "                            'Test' : [test_score,  f1_score(Y_test, rf.predict(X_test), average='weighted')]}\n",
    "\n",
    "        if test_score > best_test[idx]:\n",
    "            best_test[idx] = test_score\n",
    "            best_test_model[idx] = 'rf'\n",
    "\n",
    "        del rf\n",
    "        knn = KNeighborsClassifier()\n",
    "        param_distributions = {\"n_neighbors\": [3,4,5,7,10],\n",
    "                               \"weights\": ['uniform', 'distance'],\n",
    "                               \"leaf_size\": list(range(1,12)),\n",
    "                               \"p\": list(range(1,3))\n",
    "                              }\n",
    "        search = RandomizedSearchCV(knn, param_distributions,\n",
    "                                       n_iter=n_iter,\n",
    "                                       verbose = 0,\n",
    "                                       cv = StratifiedKFold(cv),\n",
    "                                       n_jobs=-1,\n",
    "                                       error_score = 'raise',\n",
    "                                       random_state=random_state).fit(X_train, Y_train)\n",
    "\n",
    "        knn = search.best_estimator_\n",
    "        dict_best_params['knn '+ data_dfs_names[idx]] = search.best_params_\n",
    "\n",
    "        cv_score = cross_val_score(knn, X_train, Y_train,  cv=StratifiedKFold(cv), n_jobs=-1, scoring='roc_auc', error_score='raise')\n",
    "        test_score = ml_hlp.get_AUC_ROC_value(X_test, Y_test, knn)\n",
    "        knn_dict[data_dfs_names[idx]] = {'Train': [ml_hlp.get_AUC_ROC_value(X_train, Y_train, knn)], \n",
    "                            'CV {0}'.format(cv): [cv_score.mean(), cv_score.std()],\n",
    "                            'Test' : [test_score, f1_score(Y_test, knn.predict(X_test), average='weighted')]}\n",
    "\n",
    "        if test_score > best_test[idx]:\n",
    "            best_test[idx] = test_score\n",
    "            best_test_model[idx] = 'knn'\n",
    "\n",
    "        del knn\n",
    "        mlp = MLPClassifier(random_state=random_state, max_iter=1200, \n",
    "                            learning_rate='adaptive', batch_size='auto',\n",
    "                            early_stopping=True)\n",
    "\n",
    "        param_distributions = {\"hidden_layer_sizes\": [(7,3), (5,2), (100,)],\n",
    "                               \"activation\": ['tanh', 'logistic','relu'],\n",
    "                               \"solver\": ['adam', 'lbfgs'],\n",
    "                               \"alpha\":  loguniform(0.0001, 1)\n",
    "                               }\n",
    "\n",
    "        search = RandomizedSearchCV(mlp, param_distributions,\n",
    "                                       n_iter=n_iter,\n",
    "                                       verbose = 0,\n",
    "                                       cv = StratifiedKFold(cv),\n",
    "                                       n_jobs=-1,\n",
    "                                       error_score = 'raise',\n",
    "                                       random_state=random_state).fit(X_train, Y_train)\n",
    "\n",
    "        mlp = search.best_estimator_\n",
    "        dict_best_params['mlp '+ data_dfs_names[idx]] = search.best_params_\n",
    "\n",
    "        cv_score = cross_val_score(mlp, X_train, Y_train,  cv=StratifiedKFold(cv), n_jobs=-1, scoring='roc_auc', error_score='raise')\n",
    "        test_score = ml_hlp.get_AUC_ROC_value(X_test, Y_test, mlp)\n",
    "        mlp_dict[data_dfs_names[idx]] = {'Train': [ml_hlp.get_AUC_ROC_value(X_train, Y_train, mlp)], \n",
    "                            'CV {0}'.format(cv): [cv_score.mean(), cv_score.std()],\n",
    "                            'Test' : [test_score,  f1_score(Y_test, mlp.predict(X_test), average='weighted')]}\n",
    "\n",
    "        if test_score > best_test[idx]:\n",
    "            best_test[idx] = test_score\n",
    "            best_test_model[idx] = 'mlp'\n",
    "\n",
    "    #     print('%d dict is done'%_dict)\n",
    "        del X_train, Y_train, X_test, Y_test\n",
    "    print(\"The set with cv {0} and split size {1} done.\".format(cv, split_size))\n",
    "    print(\"Best test models: \", best_test_model)\n",
    "    print(\"With test scores: \", best_test)\n",
    "    #############################################################################\n",
    "    to_be_saved_dicts = [opls_dict, svm_dict, rf_dict, knn_dict, mlp_dict]\n",
    "    names = ['opls', 'svm', 'rf', 'knn', 'mlp']\n",
    "    save_file_name = r\"...\\MEX\\PekLung\\results\\binary\"\n",
    "\n",
    "    for i in range(len(to_be_saved_dicts)):\n",
    "        results[names[i]] = to_be_saved_dicts[i]\n",
    "    file_path = save_file_name + r\"\\best_results\\2filterBo_cv_{0}_split_size_{1}\".format(cv, split_size) \n",
    "\n",
    "    hlp.write_dict_as_json_file(results, \n",
    "                                file_path = file_path)\n",
    "\n",
    "    file_path = save_file_name + r\"\\best_params\\2filterBo_cv_{0}_split_size_{1}\".format(cv, split_size) \n",
    "    hlp.write_dict_as_json_file(dict_best_params, \n",
    "                                file_path = file_path)\n",
    "    ###############################################################################\n",
    "    approaches = list(results.keys()) # ['opls', 'svm', 'rf', 'knn', 'mlp']\n",
    "    sets_names = list(results[approaches[0]].keys()) # ['All variables', '70 variables', '7 back. variables', '63 descriptors ']\n",
    "    x_labels = [set_name[0:5] for set_name in sets_names] # ['All v', '70 va', '63 de',  '7 bac']\n",
    "    splits_names = list(results[approaches[0]][sets_names[0]].keys()) # ['Train', 'CV 6', 'Test']\n",
    "    plot_dict = dict()\n",
    "    for split in splits_names:\n",
    "        tmp_dict_approach = dict()\n",
    "        for approach_idx in range(len(approaches)):\n",
    "            df = pd.DataFrame(results[approaches[approach_idx]])\n",
    "            tmp_dict_set = dict()\n",
    "            for column in df.columns:\n",
    "                tmp_dict_set[column] = df.loc[split, column][0]\n",
    "            tmp_dict_approach[approaches[approach_idx]] = tmp_dict_set\n",
    "        plot_dict[split] = tmp_dict_approach\n",
    "\n",
    "    plt.figure(figsize=(20,5))\n",
    "    for i in range(len(splits_names)):\n",
    "        split_name = splits_names[i]\n",
    "        result_df = pd.DataFrame(plot_dict[split_name])\n",
    "\n",
    "        approaches = result_df.columns\n",
    "        variables = list(result_df[approaches[i]].index)\n",
    "\n",
    "        for ii in range(len(approaches)):\n",
    "            plt.subplot(1,3,i+1)\n",
    "            plt.xticks(np.arange(len(x_labels))+0.25, x_labels, weight = 'semibold', fontsize=15)\n",
    "            plt.yticks(np.arange(0,1.1,0.05), weight = 'roman', fontsize=12)\n",
    "            plt.bar(x = np.arange(len(variables))+(ii*0.15), height=result_df[approaches[ii]], width=0.15, \n",
    "                    label = approaches[ii], alpha=0.8)\n",
    "            plt.title('{}'.format(split_name), fontsize=18, weight = 'semibold')\n",
    "\n",
    "            plt.legend(loc='lower left', fontsize=15)#bbox_to_anchor=(1., 1.))#)\n",
    "            plt.ylabel('values')\n",
    "            plt.xlabel('different feature sets')\n",
    "            plt.plot([-0.2, 3.8], [0.5, 0.5], \"k--\")\n",
    "    save_file_name = r\"...\\MEX\\data_imgs\\results_binary\\new_results\"\n",
    "    plt.tight_layout()\n",
    "    file_path = save_file_name + r\"\\2filterBo_cv_{0}_split_size_{1}\".format(cv, split_size)+\".pdf\"\n",
    "    plt.savefig(file_path)\n",
    "#     plt.show()\n",
    "    all_test_dicts[str(combs)] = plot_dict['Test']\n",
    "    \n",
    "file_path = r\"...\\MEX\\PekLung\\results\\binary\\best_results\\2filterBo_test\"\n",
    "hlp.write_dict_as_json_file(all_test_dicts, \n",
    "                            file_path = file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approaches = list(results.keys()) # ['opls', 'svm', 'rf', 'knn', 'mlp']\n",
    "sets_names = list(results[approaches[0]].keys()) # ['All variables', '70 variables', '7 back. variables', '63 descriptors ']\n",
    "x_labels = [set_name for set_name in sets_names] # ['All v', '70 va', '63 de',  '7 bac']\n",
    "splits_names = list(results[approaches[0]][sets_names[0]].keys()) # ['Train', 'CV 6', 'Test']\n",
    "plot_dict = dict()\n",
    "for split in splits_names:\n",
    "    tmp_dict_approach = dict()\n",
    "    for approach_idx in range(len(approaches)):\n",
    "        df = pd.DataFrame(results[approaches[approach_idx]])\n",
    "        tmp_dict_set = dict()\n",
    "        for column in df.columns:\n",
    "            tmp_dict_set[column] = df.loc[split, column][0]\n",
    "        tmp_dict_approach[approaches[approach_idx]] = tmp_dict_set\n",
    "    plot_dict[split] = tmp_dict_approach\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "for i in range(len(splits_names)):\n",
    "    split_name = splits_names[i]\n",
    "    result_df = pd.DataFrame(plot_dict[split_name])\n",
    "\n",
    "    approaches = result_df.columns\n",
    "    variables = list(result_df[approaches[i]].index)\n",
    "\n",
    "    for ii in range(len(approaches)):\n",
    "        plt.subplot(1,3,i+1)\n",
    "        plt.xticks(np.arange(len(x_labels))+0.25, x_labels, weight = 'semibold', fontsize=15)\n",
    "        plt.yticks(np.arange(0,1.1,0.05), weight = 'roman', fontsize=12)\n",
    "        plt.bar(x = np.arange(len(variables))+(ii*0.15), height=result_df[approaches[ii]], width=0.15, \n",
    "                label = approaches[ii], alpha=0.8)\n",
    "        plt.title('{}'.format(split_name), fontsize=18, weight = 'semibold')\n",
    "\n",
    "        plt.legend(loc='lower left', fontsize=15)#bbox_to_anchor=(1., 1.))#)\n",
    "        plt.ylabel('values')\n",
    "        plt.xlabel('different feature sets')\n",
    "        plt.plot([-0.2, 2], [0.5, 0.5], \"k--\")\n",
    "save_file_name = r\"...\\MEX\\data_imgs\\results_binary\\new_results\"\n",
    "plt.tight_layout()\n",
    "file_path = save_file_name + r\"\\2filterBo_cv_{0}_split_size_{1}\".format(cv, split_size)+\".pdf\"\n",
    "plt.savefig(file_path)\n",
    "#     plt.show()\n",
    "all_test_dicts[str(combs)] = plot_dict['Test']\n",
    "\n",
    "file_path = r\"...\\MEX\\PekLung\\results\\binary\\best_results\\2filterBo_test\"\n",
    "hlp.write_dict_as_json_file(all_test_dicts, \n",
    "                        file_path = file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
